{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from itertools import filterfalse\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Script Takes in Fed Minutes Data and applies it to Logistic Regression, Random Forest and XGBoost to predict Bull or Bear Markets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disabling warnings below only to supress warnings from invalid gridsearch combinations that yield no score in Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('Excel_data/FED_window_df.csv') # generated from window_extraction_v2. This is training and test data \n",
    "df =df.drop(columns=['Unnamed: 0']) # adds a column on import index false wont remove it\n",
    "column_list = df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the NLP Metrics to Test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick any combination from the list below as input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP_data = ['cosine_sim', 'bertopic_num', 'LDA_1', 'LDA_2', 'LDA_3', 'LDA_4',\n",
    "#       'LDA_5', 'LDA_6', 'LDA_7', 'LDA_8', 'LDA_9', 'LDA_max_value', 'w2v_1',\n",
    "#       'w2v_2', 'w2v_3', 'w2v_4', 'w2v_5', 'w2v_mean', 'd2v_1', 'd2v_2',\n",
    "#       'd2v_3', 'd2v_4', 'd2v_5', 'd2v_6', 'd2v_7', 'd2v_8', 'd2v_9', 'd2v_10',\n",
    "#       'd2v_mean', 'd2v_umap_first_component', 'd2v_umap_second_component',\n",
    "#       'Sent_TFMR','USE_Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Chosen Parameters into the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_metric = ['d2v_umap_first_component', 'd2v_umap_second_component', 'USE_Score','bertopic_num']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre built lists for parsing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = ['XLE_Adj Close', 'XLU_Adj Close', 'XLK_Adj Close', 'XLB_Adj Close', 'XLP_Adj Close', \n",
    "       'XLY_Adj Close', 'XLI_Adj Close', 'XLC_Adj Close', 'XLV_Adj Close', 'XLF_Adj Close', \n",
    "       'XLRE_Adj Close', 'HYBL_Adj Close', 'SJNK_Adj Close', 'SPTI_Adj Close', 'cosine_sim', 'bertopic_num', 'LDA_1', 'LDA_2', 'LDA_3', \n",
    "       'LDA_4', 'LDA_5', 'LDA_6', 'LDA_7', 'LDA_8', 'LDA_9', 'LDA_max_value', 'w2v_1', 'w2v_2', 'w2v_3', 'w2v_4', 'w2v_5', \n",
    "       'w2v_mean', 'd2v_1', 'd2v_2', 'd2v_3', 'd2v_4', 'd2v_5', 'd2v_6', 'd2v_7', 'd2v_8', 'd2v_9', 'd2v_10', 'd2v_mean', \n",
    "       'd2v_umap_first_component', 'd2v_umap_second_component', 'USE_Score', 'Fisher_left', 'Plosser_left', 'Bernanke_left',\n",
    "        'Geithner_left', 'Yellen_left', 'Associate Director_left', 'Brexit_left', 'Jerome H. Powell_left', 'John C. Williams_left', \n",
    "        'Raphael W. Bostic_left', 'SecretaryMr_left', 'Lockhart_left', 'Cumming_left', 'GSE_left', 'KrosznerMs_left', 'PianaltoMr_left',\n",
    "         'Associate Directors_left', 'MMIFF_left', 'MBS_left', 'Lacker_left', 'B. Any_left', 'Dudley_left', 'Williams_left', 'Kohn_left', \n",
    "         'Sack_left', 'Bid_left', 'ChairmanMr_left', 'Duke_left', 'William C. Dudley_left', 'James Bullard_left', 'Thomas M. Hoenig_left',\n",
    "          'Hoenig_left', 'Ben Bernanke_left', 'Elizabeth Duke_left', 'Charles L. Evans_left', 'Richard W. Fisher_left', 'Sandra Pianalto_left', \n",
    "          'Daniel K. Tarullo_left', 'William B. English_left', 'Charles I. Plosser_left', 'Janet L. Yellen_left', 'Loretta J. Mester_left',\n",
    "           'Narayana Kocherlakota_left', 'Kocherlakota_left', 'Senior Adviser_left', 'Stanley Fischer_left', 'Brian F. Madigan_left',\n",
    "            'Patrick Harker_left', 'Tools_left', 'Mester_left', 'Counsel_left', 'Jeffrey M. Lacker_left', 'Kashkari_left', \n",
    "            'Mark L. Mullinix_left', 'Randal K. Quarles_left', 'Hurricanes Harvey_left', 'Irma_left', 'Maria_left', 'James A. Clouse_left', \n",
    "            'Esther L. George_left', 'Robert S. Kaplan_left', 'Neel Kashkari_left', 'YCT_left', 'FIMA_left', 'Thomas_left', \n",
    "            'Thomas Laubach_left', 'Chair Powell_left', 'COVID-19_left', 'Christopher J. Waller_left', 'Lisa D. Cook_left', \n",
    "            'Austan D. Goolsbee_left', 'Lorie K. Logan_left', 'Sent_TFMR', 'Fisher_right', 'Plosser_right', 'Bernanke_right', \n",
    "            'Geithner_right', 'Yellen_right', 'Associate Director_right', 'Brexit_right', 'Jerome H. Powell_right', \n",
    "            'John C. Williams_right', 'Raphael W. Bostic_right', 'SecretaryMr_right', 'Lockhart_right', 'Cumming_right', 'GSE_right',\n",
    "             'KrosznerMs_right', 'PianaltoMr_right', 'Associate Directors_right', 'MMIFF_right', 'MBS_right', 'Lacker_right',\n",
    "              'B. Any_right', 'Dudley_right', 'Williams_right', 'Kohn_right', 'Sack_right', 'Bid_right', 'ChairmanMr_right', \n",
    "              'Duke_right', 'William C. Dudley_right', 'James Bullard_right', 'Thomas M. Hoenig_right', 'Hoenig_right', \n",
    "              'Ben Bernanke_right', 'Elizabeth Duke_right', 'Charles L. Evans_right', 'Richard W. Fisher_right', 'Sandra Pianalto_right',\n",
    "               'Daniel K. Tarullo_right', 'William B. English_right', 'Charles I. Plosser_right', 'Janet L. Yellen_right', \n",
    "               'Loretta J. Mester_right', 'Narayana Kocherlakota_right', 'Kocherlakota_right', 'Senior Adviser_right', \n",
    "               'Stanley Fischer_right', 'Brian F. Madigan_right', 'Patrick Harker_right', 'Tools_right', 'Mester_right', \n",
    "               'Counsel_right', 'Jeffrey M. Lacker_right', 'Kashkari_right', 'Mark L. Mullinix_right', 'Randal K. Quarles_right', \n",
    "               'Hurricanes Harvey_right', 'Irma_right', 'Maria_right', 'James A. Clouse_right', 'Esther L. George_right', \n",
    "               'Robert S. Kaplan_right', 'Neel Kashkari_right', 'YCT_right', 'FIMA_right', 'Thomas_right', 'Thomas Laubach_right', \n",
    "               'Chair Powell_right', 'COVID-19_right', 'Christopher J. Waller_right', 'Lisa D. Cook_right', 'Austan D. Goolsbee_right',\n",
    "                'Lorie K. Logan_right', 'Return_Next_FOMC XLE', 'Return_Next_FOMC XLU', 'Return_Next_FOMC XLK', \n",
    "                'Return_Next_FOMC XLB', 'Return_Next_FOMC XLP', 'Return_Next_FOMC XLY', 'Return_Next_FOMC XLI', 'Return_Next_FOMC XLC',\n",
    "                 'Return_Next_FOMC XLV', 'Return_Next_FOMC XLF', 'Return_Next_FOMC XLRE', 'Return_Next_FOMC TLT', 'Return_Next_FOMC HYBL',\n",
    "                  'Return_Next_FOMC SJNK', 'Return_Next_FOMC SPTI']\n",
    "\n",
    "\n",
    "\n",
    "NLP_testing_list = list(filterfalse(NLP_metric.__contains__,df_data)) # this removes all other NLP columns except for the desired test cases\n",
    "\n",
    "df = df.loc[:, ~df.columns.isin(NLP_testing_list)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out list to verify the desired NLP columns are included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'SPY_Adj Close',\n",
       " 'SPY_EMA',\n",
       " 'SPY_RSI',\n",
       " 'SPY_MACD',\n",
       " 'SPY_Signal',\n",
       " 'SPY_MACD_minus_signal',\n",
       " 'TLT_Adj Close',\n",
       " 'TLT_EMA',\n",
       " 'TLT_RSI',\n",
       " 'TLT_MACD',\n",
       " 'TLT_Signal',\n",
       " 'TLT_MACD_minus_signal',\n",
       " 'HYXF_Adj Close',\n",
       " 'LQD_Adj Close',\n",
       " 'bertopic_num',\n",
       " 'd2v_umap_first_component',\n",
       " 'd2v_umap_second_component',\n",
       " 'USE_Score',\n",
       " 'Return_Next_FOMC',\n",
       " 'Return_Next_FOMC LQD',\n",
       " 'Bull_Bear']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.tail(-1) \n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "#Imputing several values.\n",
    "# Some metrics generate NAN or infinity values which cannot be handled by the ML algorithms below\n",
    "\n",
    "# having to replace 2 infinity values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "df[:] = imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Bull_Bear']] # separate out training and test data\n",
    "X = df.drop(columns=['Bull_Bear','Return_Next_FOMC','SPY_Adj Close','TLT_Adj Close']) # removing these to reduce target contamination in X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits = 4,test_size=30)\n",
    "for train_index, test_index in tss.split(X):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index,:]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out NLP metrics for A/B Testing    \n",
    "X_train_base = X_train.loc[:, ~X_train.columns.isin(NLP_metric)]\n",
    "X_test_base = X_test.loc[:, ~X_test.columns.isin(NLP_metric)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data must be Scaled for Logistic Regression \n",
    "\n",
    "#Values without NLP data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_base.values)\n",
    "X_base_train_scaled = scaler.transform(X_train_base.values)\n",
    "X_base_test_scaled = scaler.transform(X_test_base.values)\n",
    "\n",
    "#Values with NLP data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train.values)\n",
    "X_train_scaled = scaler.transform(X_train.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Grid Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_grid = {\n",
    "    'solver': ['newton-cg','lbfgs', 'liblinear'],\n",
    "    'penalty': ['none','l1', 'l2','elasticnet'],\n",
    "    'C': loguniform(1e-5, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_base(reg_grid,X_base_train_scaled,X_base_test_scaled,y_test):\n",
    "    clf = []\n",
    "    clf = LogisticRegression(random_state=42)\n",
    "    reg_cv = RandomizedSearchCV(clf,reg_grid, cv=10,n_iter=100,scoring='roc_auc',verbose=5,n_jobs=-1)\n",
    "    _ = reg_cv.fit(X_base_train_scaled, np.ravel(y_train))\n",
    "    reg_cv.best_params_\n",
    "    clf = LogisticRegression(**reg_cv.best_params_,random_state=42)\n",
    "    clf.fit(X_base_train_scaled, np.ravel(y_train))\n",
    "    yhat = clf.predict(X_base_test_scaled)\n",
    "    acc_reg = accuracy_score(y_test,yhat)\n",
    "    print('Accuracy')\n",
    "    print(acc_reg)\n",
    "    return acc_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_NLP(reg_grid,X_train_scaled,X_test_scaled,y_test):\n",
    "    clf = []\n",
    "    clf = LogisticRegression(random_state=42)\n",
    "    reg_cv = RandomizedSearchCV(clf,reg_grid, cv=10,n_iter=100,scoring='roc_auc',verbose=5,n_jobs=-1)\n",
    "    _ = reg_cv.fit(X_train_scaled, np.ravel(y_train))\n",
    "    reg_cv.best_params_\n",
    "    clf = LogisticRegression(**reg_cv.best_params_,random_state=42)\n",
    "    clf.fit(X_train_scaled, np.ravel(y_train))\n",
    "    yhat = clf.predict(X_test_scaled)\n",
    "    acc_reg = accuracy_score(y_test,yhat)\n",
    "    print('Accuracy With NLP ')\n",
    "    print(acc_reg)\n",
    "    return acc_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** Iteration *****  1\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.5333333333333333\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.7\n",
      "\n",
      "\n",
      "***** Iteration *****  2\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6666666666666666\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.7\n",
      "\n",
      "\n",
      "***** Iteration *****  3\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.7\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.6666666666666666\n",
      "\n",
      "\n",
      "***** Iteration *****  4\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6666666666666666\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.7\n",
      "\n",
      "\n",
      "***** Iteration *****  5\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6666666666666666\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.6666666666666666\n",
      "\n",
      "\n",
      "***** Iteration *****  6\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6666666666666666\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.7\n",
      "\n",
      "\n",
      "***** Iteration *****  7\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6666666666666666\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.6666666666666666\n",
      "\n",
      "\n",
      "***** Iteration *****  8\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.7\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.7\n",
      "\n",
      "\n",
      "***** Iteration *****  9\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.5333333333333333\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.7\n",
      "\n",
      "\n",
      "***** Iteration *****  10\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6666666666666666\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP \n",
      "0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg_vec = []\n",
    "log_reg_NLP_vec =[]\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    print('\\n')\n",
    "    print('***** Iteration ***** ',i+1)\n",
    "    \n",
    "    # Base Monte Carlo\n",
    "    log_reg_score = log_reg_base(reg_grid,X_base_train_scaled,X_base_test_scaled,y_test)\n",
    "    log_reg_vec.append(log_reg_score)\n",
    "\n",
    "    #NLP Monte Carlo\n",
    "    log_reg_NLP_score = log_reg_NLP(reg_grid,X_train_scaled,X_test_scaled,y_test)\n",
    "    log_reg_NLP_vec.append(log_reg_NLP_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Logistic Regression Accuracy:  0.6466666666666667\n",
      "NLP Logistic Regression Accuracy:  0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Average Accuracy Scores\n",
    "LR_base_AVG = np.mean(log_reg_vec)\n",
    "LR_NLP_AVG = np.mean(log_reg_NLP_vec)\n",
    "print('Base Logistic Regression Accuracy: ',LR_base_AVG)\n",
    "print('NLP Logistic Regression Accuracy: ',LR_NLP_AVG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "criterion = ['gini', 'entropy']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 20, num = 20)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 7]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'criterion': criterion,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_base(random_grid,X_train_base,X_test_base,y_train,y_test):    \n",
    "\n",
    "    clf_RF = RandomForestClassifier(random_state=42)\n",
    "    rf_random2 = RandomizedSearchCV(estimator = clf_RF, param_distributions = random_grid, n_iter = 10, \n",
    "                                cv = 10, verbose=2, n_jobs = -1)\n",
    "    rf_random2.fit(X_train_base, y_train.values.ravel())\n",
    "    clf_RF = RandomForestClassifier(**rf_random2.best_params_,random_state=42)\n",
    "    clf_RF.fit(X_train_base, y_train.values.ravel())\n",
    "    yhat = clf_RF.predict(X_test_base)\n",
    "    acc_RF = accuracy_score(y_test, yhat)\n",
    "\n",
    "    print('Accuracy')\n",
    "    print(acc_RF)\n",
    "\n",
    "\n",
    "    return acc_RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_NLP(random_grid,X_train,X_test,y_train,y_test):    \n",
    "\n",
    "    clf_RF = RandomForestClassifier(random_state=42)\n",
    "    rf_random2 = RandomizedSearchCV(estimator = clf_RF, param_distributions = random_grid, n_iter = 10, \n",
    "                                cv = 10, verbose=2, n_jobs = -1)\n",
    "    rf_random2.fit(X_train, y_train.values.ravel())\n",
    "    clf_RF = RandomForestClassifier(**rf_random2.best_params_,random_state=42)\n",
    "    clf_RF.fit(X_train, y_train.values.ravel())\n",
    "    yhat = clf_RF.predict(X_test)\n",
    "    acc_RF = accuracy_score(y_test, yhat)\n",
    "\n",
    "    print('Accuracy With NLP')\n",
    "    print(acc_RF)\n",
    "\n",
    "\n",
    "    return acc_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** Iteration *****  1\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy\n",
      "0.7666666666666667\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  2\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy\n",
      "0.8\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy With NLP\n",
      "0.7666666666666667\n",
      "\n",
      "\n",
      "***** Iteration *****  3\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy\n",
      "0.7\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy With NLP\n",
      "0.7666666666666667\n",
      "\n",
      "\n",
      "***** Iteration *****  4\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy\n",
      "0.7666666666666667\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy With NLP\n",
      "0.7666666666666667\n",
      "\n",
      "\n",
      "***** Iteration *****  5\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy\n",
      "0.7\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "RF_vec = []\n",
    "RF_NLP_vec =[]\n",
    "\n",
    "\n",
    "for i in range(0,5):\n",
    "    print('\\n')\n",
    "    print('***** Iteration ***** ',i+1)\n",
    "    # Base Monte Carlo\n",
    "    RF_base_score = RF_base(random_grid,X_train_base,X_test_base,y_train,y_test)\n",
    "    RF_vec.append(RF_base_score)\n",
    "\n",
    "    #NLP Monte Carlo\n",
    "    RF_NLP_score = RF_NLP(random_grid,X_train,X_test,y_train,y_test)\n",
    "    RF_NLP_vec.append(RF_NLP_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Random Forest Accuracy:  0.7466666666666667\n",
      "NLP Random Forest Accuracy:  0.7533333333333333\n"
     ]
    }
   ],
   "source": [
    "RF_base_AVG = np.mean(RF_vec)\n",
    "RF_NLP_vec = np.mean(RF_NLP_vec)\n",
    "\n",
    "print('Base Random Forest Accuracy: ',RF_base_AVG)\n",
    "print('NLP Random Forest Accuracy: ',RF_NLP_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [1,2,3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05,0.1,0.15],\n",
    "    \"gamma\": [0, 0.25, 1,1.25,1.5,1.75],\n",
    "    \"reg_lambda\": [0, 1, 10,50,100,110,120],\n",
    "    \"scale_pos_weight\": [1, 3, 5,7,9,11],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XG_NLP(param_grid,X_train,X_test,y_train,y_test):\n",
    "\n",
    "    #Optimizing through grid search\n",
    "    xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\",random_state=42)\n",
    "    grid_cv = RandomizedSearchCV(xgb_cl,param_grid, cv=10,n_iter=100,scoring='roc_auc',verbose=5,n_jobs=-1)\n",
    "    _ = grid_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Rebuild optimized clasifier\n",
    "    xgb_cl = xgb.XGBClassifier(**grid_cv.best_params_,objective=\"binary:logistic\",random_state=42)\n",
    "    xgb_cl.fit(X_train, y_train)\n",
    "    yhat = xgb_cl.predict(X_test)\n",
    "    acc_nlp = accuracy_score(y_test,yhat)\n",
    "    print('Accuracy With NLP')\n",
    "    print(acc_nlp)\n",
    "\n",
    "\n",
    "    return (acc_nlp, grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XG_Base(param_grid,X_train_base,X_test_base,y_train,y_test):\n",
    "\n",
    "    xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\",random_state=42)\n",
    " \n",
    "    grid_cv2 = RandomizedSearchCV(xgb_cl,param_grid, cv=10,n_iter=100,scoring='roc_auc',verbose=5,n_jobs=-1)\n",
    "    _ = grid_cv2.fit(X_train_base, y_train) # base is used instead of X_train\n",
    "\n",
    "    xgb_base2 = xgb.XGBClassifier(**grid_cv2.best_params_,objective=\"binary:logistic\",random_state=42)\n",
    "\n",
    "    xgb_base2.fit(X_train_base, y_train)\n",
    "    yhat_base = xgb_base2.predict(X_test_base)\n",
    "    acc_base = accuracy_score(y_test,yhat_base)\n",
    "\n",
    "    print('Accuracy')\n",
    "    print(acc_base)\n",
    "\n",
    "    return (acc_base,grid_cv2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** Iteration *****  1\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.7333333333333333\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  2\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  3\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.7333333333333333\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  4\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  5\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.7333333333333333\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  6\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.7333333333333333\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  7\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.7\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  8\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6333333333333333\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  9\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6333333333333333\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n",
      "\n",
      "\n",
      "***** Iteration *****  10\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy\n",
      "0.6333333333333333\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "Accuracy With NLP\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "XG_vec = []\n",
    "XG_NLP_vec =[]\n",
    "XG_base_top_score = -1\n",
    "XG_top_score = -1\n",
    "for i in range(0,10):\n",
    "    print('\\n')\n",
    "    print('***** Iteration ***** ',i+1)\n",
    "    # Base Monte Carlo\n",
    "    XG_base_score,base_best_parameters = XG_Base(param_grid,X_train_base,X_test_base,y_train,y_test)\n",
    "    XG_vec.append(XG_base_score)\n",
    "    if XG_base_score > XG_base_top_score:\n",
    "        best_iter_base = base_best_parameters\n",
    "\n",
    "\n",
    "    #NLP Monte Carlo\n",
    "    XG_NLP_score,best_parameters = XG_NLP(param_grid,X_train,X_test,y_train,y_test)\n",
    "    XG_NLP_vec.append(XG_NLP_score)\n",
    "    if XG_NLP_score > XG_top_score:\n",
    "        best_iter = best_parameters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XGBoost Accuracy:  0.6733333333333332\n",
      "NLP XGBoost Accuracy:  0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "XG_base_AVG = np.mean(XG_vec)\n",
    "XG_NLP_AVG = np.mean(XG_NLP_vec)\n",
    "\n",
    "print('Base XGBoost Accuracy: ',XG_base_AVG)\n",
    "print('NLP XGBoost Accuracy: ',XG_NLP_AVG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Best Params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6333333333333333"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\",random_state=42)\n",
    "grid_cv2 = RandomizedSearchCV(xgb_cl,param_grid, cv=10,n_iter=100,scoring='roc_auc',verbose=5,n_jobs=-1)\n",
    "_ = grid_cv2.fit(X_train_base, y_train) # base is used instead of X_train\n",
    "xgb_base2 = xgb.XGBClassifier(**best_iter_base,objective=\"binary:logistic\",random_state=42)\n",
    "\n",
    "xgb_base2.fit(X_train_base, y_train)\n",
    "yhat_base = xgb_base2.predict(X_test_base)\n",
    "acc_base = accuracy_score(y_test,yhat_base)\n",
    "acc_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\",random_state=42)\n",
    "grid_cv2 = RandomizedSearchCV(xgb_cl,param_grid, cv=10,n_iter=100,scoring='roc_auc',verbose=5,n_jobs=-1)\n",
    "_ = grid_cv2.fit(X_train_base, y_train) # base is used instead of X_train\n",
    "xgb_base2 = xgb.XGBClassifier(**best_iter,objective=\"binary:logistic\",random_state=42)\n",
    "\n",
    "xgb_base2.fit(X_train, y_train)\n",
    "yhat = xgb_base2.predict(X_test)\n",
    "acc_base = accuracy_score(y_test,yhat)\n",
    "acc_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = y_test.copy()\n",
    "comp_df['Prediction'] = yhat\n",
    "comp_df['Base_Prediction']=yhat_base\n",
    "comp_df.to_csv('Excel_data/Predictions_random.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print out the List of All Predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction is the model with NLP Included and Base is the non NLP version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bull_Bear</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Base_Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-02</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bull_Bear  Prediction  Base_Prediction\n",
       "Date                                              \n",
       "2019-10-30        1.0           1                1\n",
       "2019-12-11        0.0           0                1\n",
       "2020-01-29        0.0           0                1\n",
       "2020-03-15        0.0           1                1\n",
       "2020-04-29        1.0           1                1\n",
       "2020-06-10        0.0           0                0\n",
       "2020-07-29        1.0           0                1\n",
       "2020-09-16        0.0           0                1\n",
       "2020-11-05        1.0           1                1\n",
       "2020-12-16        0.0           0                1\n",
       "2021-01-27        1.0           0                1\n",
       "2021-03-17        1.0           0                1\n",
       "2021-04-28        0.0           0                0\n",
       "2021-06-16        1.0           1                1\n",
       "2021-07-28        0.0           0                1\n",
       "2021-09-22        1.0           1                1\n",
       "2021-11-03        0.0           0                0\n",
       "2021-12-15        0.0           1                1\n",
       "2022-01-26        1.0           1                1\n",
       "2022-03-16        0.0           1                1\n",
       "2022-05-04        0.0           1                1\n",
       "2022-06-15        1.0           1                1\n",
       "2022-07-27        0.0           0                0\n",
       "2022-09-21        1.0           1                1\n",
       "2022-11-02        1.0           1                1\n",
       "2022-12-14        0.0           0                1\n",
       "2023-02-01        0.0           0                1\n",
       "2023-03-22        1.0           1                1\n",
       "2023-05-03        1.0           0                1\n",
       "2023-06-14        0.0           0                0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Tabulation of Missed Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bull_Bear          8\n",
       "Prediction         8\n",
       "Base_Prediction    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df\n",
    "NLP_counter = comp_df[comp_df['Prediction']!=comp_df['Bull_Bear']].count()\n",
    "NLP_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Analysis of Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No NLP</td>\n",
       "      <td>66.33</td>\n",
       "      <td>63.33</td>\n",
       "      <td>73.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformer Sentiment</td>\n",
       "      <td>58.00</td>\n",
       "      <td>66.66</td>\n",
       "      <td>73.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cosine Similarity</td>\n",
       "      <td>67.66</td>\n",
       "      <td>66.66</td>\n",
       "      <td>68.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USE Score</td>\n",
       "      <td>65.99</td>\n",
       "      <td>66.66</td>\n",
       "      <td>75.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bert Topic Modeling</td>\n",
       "      <td>66.33</td>\n",
       "      <td>70.00</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LDA max Value</td>\n",
       "      <td>66.33</td>\n",
       "      <td>69.33</td>\n",
       "      <td>69.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LDA Mosaic</td>\n",
       "      <td>67.99</td>\n",
       "      <td>68.66</td>\n",
       "      <td>73.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Doc2Vec Mean</td>\n",
       "      <td>68.33</td>\n",
       "      <td>71.33</td>\n",
       "      <td>71.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Doc2Vec Mosaic</td>\n",
       "      <td>63.00</td>\n",
       "      <td>71.33</td>\n",
       "      <td>73.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D2V UMAP 1st Comp</td>\n",
       "      <td>62.66</td>\n",
       "      <td>69.33</td>\n",
       "      <td>71.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D2V UMAP 2nd Comp</td>\n",
       "      <td>64.99</td>\n",
       "      <td>66.66</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D2V UMAP Mosaic</td>\n",
       "      <td>66.66</td>\n",
       "      <td>69.33</td>\n",
       "      <td>75.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Named Entity</td>\n",
       "      <td>60.66</td>\n",
       "      <td>72.00</td>\n",
       "      <td>71.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Top 3 Metrics</td>\n",
       "      <td>67.00</td>\n",
       "      <td>67.99</td>\n",
       "      <td>76.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Metric  Logistic Regression  Random Forest  XGBoost\n",
       "0                  No NLP                66.33          63.33    73.66\n",
       "1   Transformer Sentiment                58.00          66.66    73.00\n",
       "2       Cosine Similarity                67.66          66.66    68.66\n",
       "3               USE Score                65.99          66.66    75.66\n",
       "4     Bert Topic Modeling                66.33          70.00    75.00\n",
       "5           LDA max Value                66.33          69.33    69.00\n",
       "6              LDA Mosaic                67.99          68.66    73.00\n",
       "7            Doc2Vec Mean                68.33          71.33    71.66\n",
       "8          Doc2Vec Mosaic                63.00          71.33    73.33\n",
       "9       D2V UMAP 1st Comp                62.66          69.33    71.00\n",
       "10      D2V UMAP 2nd Comp                64.99          66.66    75.00\n",
       "11        D2V UMAP Mosaic                66.66          69.33    75.33\n",
       "12           Named Entity                60.66          72.00    71.00\n",
       "13          Top 3 Metrics                67.00          67.99    76.66"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These values were batch processed with the code above and saved to a csv file which is now read in as nlp_mc_Final\n",
    "\n",
    "nlp_mc = pd.read_csv('Excel_data/nlp_mc_Final.csv')\n",
    "nlp_mc = pd.DataFrame(nlp_mc)\n",
    "nlp_mc = nlp_mc.rename(columns={'Unnamed: 0':'Metric'})\n",
    "nlp_mc['Logistic Regression'] =nlp_mc['Logistic Regression']*100\n",
    "nlp_mc['Random Forest'] =nlp_mc['Random Forest']*100\n",
    "nlp_mc['XGBoost'] =nlp_mc['XGBoost']*100\n",
    "nlp_mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-B Testing Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "lightsalmon"
         },
         "name": "Logistic Regression",
         "text": [
          73.66,
          73,
          68.66,
          75.66,
          75,
          69,
          73,
          71.66,
          73.33,
          71,
          75,
          75.33,
          71,
          76.66
         ],
         "texttemplate": "%{y:0.2f}",
         "type": "bar",
         "x": [
          "No NLP",
          "Transformer Sentiment",
          "Cosine Similarity",
          "USE Score",
          "Bert Topic Modeling",
          "LDA max Value",
          "LDA Mosaic",
          "Doc2Vec Mean",
          "Doc2Vec Mosaic",
          "D2V UMAP 1st Comp",
          "D2V UMAP 2nd Comp",
          "D2V UMAP Mosaic",
          "Named Entity",
          "Top 3 Metrics"
         ],
         "y": [
          66.33,
          57.99999999999999,
          67.66,
          65.99000000000001,
          66.33,
          66.33,
          67.99,
          68.33,
          63,
          62.660000000000004,
          64.99000000000001,
          66.66,
          60.660000000000004,
          67
         ]
        },
        {
         "marker": {
          "color": "indianred"
         },
         "name": "Random Forest",
         "text": [
          73.66,
          73,
          68.66,
          75.66,
          75,
          69,
          73,
          71.66,
          73.33,
          71,
          75,
          75.33,
          71,
          76.66
         ],
         "texttemplate": "%{y:0.2f}",
         "type": "bar",
         "x": [
          "No NLP",
          "Transformer Sentiment",
          "Cosine Similarity",
          "USE Score",
          "Bert Topic Modeling",
          "LDA max Value",
          "LDA Mosaic",
          "Doc2Vec Mean",
          "Doc2Vec Mosaic",
          "D2V UMAP 1st Comp",
          "D2V UMAP 2nd Comp",
          "D2V UMAP Mosaic",
          "Named Entity",
          "Top 3 Metrics"
         ],
         "y": [
          63.33,
          66.66,
          66.66,
          66.66,
          70,
          69.33,
          68.66,
          71.33,
          71.33,
          69.33,
          66.66,
          69.33,
          72,
          67.99
         ]
        },
        {
         "marker": {
          "color": "steelblue"
         },
         "name": "XGBoost",
         "text": [
          73.66,
          73,
          68.66,
          75.66,
          75,
          69,
          73,
          71.66,
          73.33,
          71,
          75,
          75.33,
          71,
          76.66
         ],
         "textposition": "auto",
         "texttemplate": "%{y:0.1f}",
         "type": "bar",
         "x": [
          "No NLP",
          "Transformer Sentiment",
          "Cosine Similarity",
          "USE Score",
          "Bert Topic Modeling",
          "LDA max Value",
          "LDA Mosaic",
          "Doc2Vec Mean",
          "Doc2Vec Mosaic",
          "D2V UMAP 1st Comp",
          "D2V UMAP 2nd Comp",
          "D2V UMAP Mosaic",
          "Named Entity",
          "Top 3 Metrics"
         ],
         "y": [
          73.66,
          73,
          68.66,
          75.66000000000001,
          75,
          69,
          73,
          71.66,
          73.33,
          71,
          75,
          75.33,
          71,
          76.66
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 9
          },
          "showarrow": false,
          "text": "Best",
          "x": 13.27,
          "y": 71,
          "yshift": 40
         }
        ],
        "barmode": "group",
        "font": {
         "size": 14
        },
        "legend": {
         "x": 0.8,
         "xanchor": "left",
         "y": 1.4,
         "yanchor": "top"
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 100
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 27
         },
         "text": "Average Model Prediction Accuracy By NLP Metric",
         "x": 0.35,
         "xref": "paper",
         "y": 0.85
        },
        "xaxis": {
         "tickangle": -45,
         "title": {
          "text": "NLP Metric"
         }
        },
        "yaxis": {
         "range": [
          50,
          85
         ],
         "title": {
          "text": "Accuracy (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "metric = nlp_mc.Metric.to_list()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=metric,\n",
    "    y=nlp_mc['Logistic Regression'],\n",
    "    name='Logistic Regression',\n",
    "    marker_color='lightsalmon',\n",
    "    texttemplate=\"%{y:0.2f}\",\n",
    "    text=nlp_mc['XGBoost'].round(2),\n",
    "    #width=0.3\n",
    "    \n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=metric,\n",
    "    y=nlp_mc['Random Forest'],\n",
    "    name='Random Forest',\n",
    "    marker_color='indianred',\n",
    "    texttemplate=\"%{y:0.2f}\",\n",
    "    text=nlp_mc['XGBoost'].round(2),\n",
    "    #width=0.3\n",
    "\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=metric,\n",
    "    y=nlp_mc['XGBoost'],\n",
    "    name='XGBoost',\n",
    "    marker_color='steelblue',\n",
    "    selectedpoints=None,\n",
    "    textposition='auto',\n",
    "    texttemplate=\"%{y:0.1f}\",\n",
    "    text=nlp_mc['XGBoost'].round(2),\n",
    "    #width=0.3\n",
    "))\n",
    "\n",
    "fig.add_annotation(x=13.27, y=71,\n",
    "            text=\"Best\",\n",
    "            showarrow=False,\n",
    "            font = dict(size = 9),\n",
    "            yshift=40)\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='group', xaxis_tickangle=-45)\n",
    "fig.update_layout(title=dict(text=\"Average Model Prediction Accuracy By NLP Metric\",font=dict(size=27),x=0.35,y=0.85,xref=\"paper\"),yaxis_title=(\"Accuracy (%)\"),xaxis_title=\"NLP Method\")\n",
    "fig.update_layout(yaxis_title=\"Accuracy (%)\",font=dict(size=12))\n",
    "fig.update_layout(yaxis_range=[50,85])\n",
    "fig.update_layout(xaxis_title=\"NLP Metric\",font=dict(size=14))\n",
    "fig.update_layout(\n",
    "    margin=dict(l=0, r=0, t=100, b=0),\n",
    ")\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=1.4,\n",
    "    xanchor=\"left\",\n",
    "    x=.80\n",
    "))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
